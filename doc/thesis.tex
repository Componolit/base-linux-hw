\documentclass[
a4paper,
12pt,
notitlepage,
parskip=half,
DIV=11,
]{scrbook}

\usepackage[utf8]{inputenx}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{graphicx}

\usepackage[numbers]{natbib}
\usepackage{cite}

\input{genode-manual/manual/img/tikz-preamble.tex}
\input{genode-manual/manual/img/tikz-common.tex}

\begin{document}
	
	\tableofcontents
	
	\chapter{Introduction}
		
	
                At the present time we are surrounded by devices that run complex software and operating systems.
		The number of these devices is still rising and their complexity is growing by the increasing amount computational resources, functionalities and interfaces.
		Also many of these devices are taking over important tasks such as smart locks or even cardiac pacemakers.
		Since most of these devices are connected to the public Internet they cannot only be accessed by their owners but anyone.
		
		Most of the modern systems run on kernels built in a monolithic manner.
		This implies that a high amount of the critical functionality such as device drivers and networking stack are implemented by them.
		All these complex software constructs run on the so called kernel mode which is the highest privileged mode it can achieve.
		It is where the operating system kernel usually runs in.
		Since it can access and control the whole system including any user processes a single vulnerability in any of its components could compromise the entire system.
		
		Furthermore the quality of this software is often bad.
		This is especially true for device drivers which have around three to seven times higher error rates than other kernel parts.
		That is even more problematic since drivers also are the majority of the code.
		While an attacker often needs to find only a single error monolithic kernels often contain thousands of them due to their large code base.
		
		Also when bugs appear in the kernel it needs in average far over one year until a fix is available.
		And even then it takes additional time until it is brought to the user.
		There are also systems that cannot be patched for different reasons.
		These will stay vulnerable for their whole lifetime. \citep{Chou:SOSP:01}
		
		A first step to mitigate this problem would be the usage of user level drivers.
		The user level is a less privileged mode than the kernel mode.
		It runs most of the software on a system including all conventional end user applications and has certain security boundaries such as user permissions or device access restrictions.
		This would not solve the problems based on the errors in the software itself but it would lower their privileges.
		A compromised driver would not be able to access and control the whole system but only a part of it.
		
		To benefit from user space drivers certain requirements need to be fulfilled.
		The driver must run completely inside the user space without any exceptions.
		At the point where it needs to run its own code inside the kernel any security advantage is gone since an attacker could escalade its privileges.
		
		% no kernel modifications 
		A second requirement are kernel interfaces that allow drivers to work completely without any further modifications to the kernel.
		This is founded on two reasons.
		First it improves operability as drivers can be loaded or patched without any influence on the kernel itself.
		Second, and more importantly, they cannot introduce further errors to the kernel.
		Any modification, even if it is only a small one done to interface with a driver can cause bugs that could compromise the security of the entire system.
		To prevent this the kernel needs to stay untouched.
		
		If an existing kernel, such as Linux, is used to fulfil these needs a suitable interface needs to be added which is then used by the drivers.
		This interface of course is itself a modification to the kernel and needs to be treated as security relevant code.
		Yet it is still much smaller than the drivers it is meant to move to the user space.
		
		% updates ?
%		These facts raise the question if we can trust these devices.
%		Many cases in the present have shown that nearly all of these devices have security issues.
%		Since the used systems are too complex to guarantee the absence of software errors the common practice is patching these devices when an error has been discovered.
%		Unfortunately the approach of fixing errors has not proven reliable.
%		Updates are often not or only for a short time available and often do not find their way to the end user.
		
		% component based systems
%		A difference to this practice are sectors where manufacturers are liable for the correctness of their products including software parts.
%		This can be achieved by enforcing specific work flows that reduce error probabilities and intensive testing.
%		But also verification with formal and mathematical methods can be used diminish the rate of faults.
%		
%		While this seems to be a solution to the current problems this approach is far from being scalable enough.
%		Comprehensive testing requires a high amount of resources that often is not available or economically reasonable.
%		Also verification requires an even higher effort and for many large projects it is far from being possible.
%		This leads to the question how the high complexity of current applications can be combined with the trustiness of comprehensively tested and verified software.
%		
%		That is the point where component based systems have their use case.
%		They separate the untrusted parts of the software from each other while providing defined ways for them to communicate with each other.
%		The component based system itself does not implement any functionality beside separation and enforcement of policies.
%		This allows a small trusted code base that is able to be verified and tested.
%		
%		The software components themselves do not need to be trusted any more.
%		Due to the separation a fault or security issue does only affect a single component and cannot spread across other applications.
%		To enforce this behaviour through all parts of the system the architecture is based on a micro kernel.
%		
%		Most of the common operating systems use a monolithic kernel.
%		This means that all drivers run in the kernel space.
%		Not only hardware accessing parts are included there but also file systems and networking stacks.
%		This leads to the problem that if only one of these drivers is compromised it can access the whole kernel and therefore the complete system.
%		All security assumptions in the user space are invalid from this point.
		
	\chapter{Background}

		
		
		\section{Monolithic kernels}
		
		Most of the widely used modern operating systems rely on monolithic kernels.
		A well known example is Linux.
		This architecture includes a big part of the operating system functionality into the kernel which has implications for software architecture and communication but also security.
		Systems based on monolithic kernels usually scale well and can use hardware in a large scale with multiple thousand processing units and terrabytes of main memory.
		
		Since all the functionality the kernel provides runs in a single address space communication between processes can be done via shared memory.
		This results in low overhead for communication and a weak isolation between components.
		And those within the kernel are even able to access any memory without restrictions.
		
		Monolithic kernels usually integrate all their components and subsystems into a single environment.
		While this makes communication between them easy it is also a pitfall if one of them fails.
		In the worst case a failing component is able to make the entire system fail.
		That is also important for security considerations.
		A single compromised component, such as networking driver, could infect the complete kernel.
		
		Due to the high integration monolithic kernels have a high complexity.
		Linux for example consists of millions of lines of code which may introduce errors.
		While automatic reviewing methods can be applied there is still a large number of manual reviews required to provide a certain quality.
		Yet this will not prevent all errors.
		
		There are still ways to modularize monolithic kernels.
		One part of this is at the source code level.
		To manage such a complex construct it is required to separate the sources of subsystems and only provide application programming interfaces between each other.
		
		Also at the binary level some kind of modularization exists in form of loadable kernel modules.
		These are parts of the kernel, that run in the same address space but can be loaded at run time.
		This is required due to the high amount of different devices that need to be supported.
		Loading all their drivers at start is not always feasible so loading only the ones needed at runtime which reduces the size of the kernel itself.
		
		It also enables third parties to make their drivers available without the need to recompile the kernel or bring their source code upstream.
		On the other hand these drivers often lack the quality of the kernel code but still run in its context which introduces a higher risk of errors. \citep{Lameter07}
		
		\section{Microkernels}
		
		Micro kernels are the contrary concept to monolithic kernel.
		Their goal is, in simple terms, to remove as much functionality as possible from the kernel and implement it outside of it.
		This aims to make the system highly modularizable and isolate failures in components from the rest of the system.
		
		As a general requirement a micro kernel should only functionality that would be impossible to implement outside the kernel.
		It also has to separate and protect applications from itself and each other.
		Any component that runs on a micro kernel must not be influenced by any other. And if two components communicate between each other the communication must be secure in regards of confidentiality and integrity.
		
		These requirements are met by different concepts.
		One of them are address spaces which are mappings from physical to virtual memory pages.
		These are given recursively to child subsystems.
		The first subsystem owns the whole physical memory in a single address space from where it can grant parts of it to another subsystem.
		Its own access to this page is then removed.
		If it wants to keep this space, for example to employ shared memory, it can map the space to the other subsystem.
		To reverse the mapping the according address space can be flushed removing it from all other subsystems except the flushing one.
		The managing of these operations is done in the kernel itself.
		While I/O memory is a does not necessarily represent physical main memory it is also managed in this context.
		
		%threads...
		The activity that happens in such an address space is called a thread.
		It is characterized through its own state including its address space, stack pointer and instruction pointer.
		Any changes the thread applies to its address space are controlled by the kernel.
		Also it cannot access address spaces of other threads.
		To be able to communicate inter process communication is used and therefore must be supported by the kernel.
		
		Inter process communication (IPC) is a defined way for two threads to communicate with each other.
		While both parties must agree to the transmission the sender controls the content while the receiver has to handle it.
		This handling includes if the contents are used at all and how they are interpreted.
		
		Beside message based IPC remote procedure calls can be used for communication.
		It does not send data to other threads but migrates the sending one to another address space.
		Both of these communication concepts need to be supervised by the kernel.
		
		On modern hardware interrupts are an often used way of devices to notify the software of events.
		This mechanism also needs to be supported on micro kernels.
		Interrupts are incorporated by empty IPC messages.
		They are sent from threads that have special ids which map to hardware interrupt ids.
		The receiving thread can conclude to the triggered interrupt by the source id. \citep{Liedtke_1995}
		
		\section{Genode}
		
		Genode aims to solve this problem through multiple ways.
		Instead of a monolithic kernel it uses microkernels.
		They provide a greater flexibility than separation kernels why keeping the size of the trusted computing base at a manageable level.
		This is accomplished for example by running device drivers as separate user space processes.
		User space applications in Genode are also managed by capabilities.
		They provide a way to allow and deny access to a certain number of system resources without the need for a global complex policy.
		Additionally to capabilities resources can be managed in a hierarchical way.
		Software components can be be partitioned into parts of different complexity.
		This helps to exclude complex parts from the trusted computing base and therefore reduce the amount of code that needs to be verified.
		The continuation of this approach leads to an application specific trusted computing base that consists of the application itself and all the parts it depends on [\ref{fig:tcb_tree}].
		\citep{genode}
		
		\begin{figure}
			\centering
			\input{genode-manual/manual/img/app_specific_tcb.tikz}
			\caption{Application based TCB \citep{genode}}
			\label{fig:tcb_tree}
		\end{figure}
		
		The Genode OS framework is the implementation of this architecture for highly secure special purpose operating systems.
		Mainly written in C++ it scales from embedded systems with only a few megabytes of memory to big systems with dynamic workloads.
		The architecture consists of a recursive sandbox structure.
		Those are controlled from their parents and separated from their siblings.
		But they can create additional sandboxes and subtrees of children.
		This creates hierarchical structures and reduces the attack surface of the system since a compromised component cannot access resources of other components.
		These components are small blocks that can create complex systems without unnecessarily increasing the trusted computing base.
		Beside being programs they can also provide other functionalities such as device drivers or protocol stacks.
		
		Genode supports multiple CPU architectures such as Intel i386 and ARM.
		Multiple microkernels such as NOVA and seL4 can be used.
		Additionally Genode provides a custom kernel implementation that in comparison to other kernels further reduces the trusted computing base.
		The current framework also provides many usable driver and application components.
		Beside common periphery drivers such as USB and Intel wireless this also includes complex application frameworks such as Qt5. \citep{genode}
		
		To debug components in the development process Genode can also be started on the current running Linux kernel.
		This is a good approach for applications but is also limited.
		Some resources cannot be used since the Linux kernel doesn't provide them to the user space, for example memory mapped IO or direct memory access.
		To develop and debug native Genode device drivers the kernel needs to act as a microkernel and provide access to these resources in Genode.
		
		Some of Genodes properties are important for the evaluation of this thesis and will be explained further.
		One is the source code management which is based on so called repositories that can include multiple sets of software components.
		The other is the session concept which implements the IPC mechanism and also provides abstractions to platform specific code.
		
		\subsection{Repositories}
		
		\subsection{Sessions}
	
	\chapter{Related work}
		
		\section{User space drivers on Linux}
		
		There have already been different approaches on using suer space drivers on Linux.
		A, in the Linux world widely known, project is Filesystem in Userspace (FUSE).
		It's target is to provide users with the ability to use custom file systems without the need to require root privileges or edit kernel code.
		To achieve this FUSE consists of two parts, a kernel module and a user space library.
		The library communicates with the kernel module to provide the necessary functionality to the user.
		While this does not access any hardware resources it shows a concept how kernel resources can be accessed from the user space. \citep{fuse}
		
		Another approach is Userspace I/O (UIO).
		UIO addresses industrial systems that often require I/O cards which only need some mapped memory and interrupts.
		These cards are available as device files on Linux which provide access to the address space of each device.
		Contrary to FUSE UIO drivers require a small kernel module that deploys access to hardware resources.
		But the driver logic can be implemented in user space.
		This gives a number of advantages for both the programmer and the user.
		Instead of kernel modules these drivers can use many tools and libraries that are not available in the kernel.
		Also bugs and crashes of the driver do not influence the kernel itself.
		While updates of kernel modules often require the recompilation of the kernel or at least a reboot of the system updates of these drivers can be done more easily. \citep{uio}
		
		\section{Rump kernels}
		
		A rump kernel provides a lightweight environment for drivers on top of an anykernel.
		The flexible anykernel architecture allows kernels to run in different configurations or modes.
		They can be created from a monolithic kernel with a moderate effort.
		While they provide an interface for rump based drivers they also preserve their monolithic properties and driver stacks. \citep{kantee}
		
		Drivers on top of a rump kernel only need to interface with it and not the underlying kernel.
		That makes this concept portable to highly different platforms such as monolithic or micro kernels.
		This is achieved by stripping away all unneeded components of a kernel and only leaving those required for drivers to work.
		At the lower part of the kernel exists a small and well defined portability layer to interface with the underlying environment.
		These concepts were implemented first by the NetBSD project. \citep{bsd_rump}\citep{fosdem_rump}\citep{rump}
		
		Rump applications and drivers are created using the so called Hypercall API.
		There are two main parts of this API.
		The first one are basic calls for applications such as those for allocating memory or using threads.
		The second is about handling I/O operations and is splitted into a virtual and a physical part.
		The virtualized calls access services provided by the host operating system such as network interfaces and protocols. \citep{rump_man} \citep{rump_platform}
		
		While system calls and access to the host systems interfaces is defined straightforward direct hardware access is not.
		With one exception the rump kernel does not have support to directly map physical memory.
		These mappings are usually represented as files on the host system.
		While these files could be used to map memory into the rump kernel they would also limit the platforms and environments where it can be hosted.
		The only exception to this are vnodes which are inode representations in memory.
		The approach of the rump kernel to solve this problem is to allocate a block of memory and copy the contents of the memory mapped by the host system back and forth.
		This works only because the vnode pages can be accessed by a single consumer at a time.
		Therefore this approach is inapplicable for memory mapped IO or volatile memory. \citep{kantee}
		
		Another important aspect of hardware drivers are interrupts.
		Hardware interrupts usually preempt the CPU which is not supported by the rump kernel.
		Instead they are implemented as host threads which then schedule the handler inside the rump kernel accordingly. \citep{kantee}
		
		While these properties speak against hardware drivers in the first place there is one example of a hardware device driver for USB devices described.
		Yet this example operates on a higher level than direct access to hardware resources.
		The BSD kernel makes USB devices accessible to the user space via \texttt{ugen} the USB generic device support.
		The rump kernel implementation of the USB driver allows to configure the access to specific USB devices at compile time. \citep{kantee} \citep{ugen}
		
		\section{Fuse}
	
	\chapter{Design and Implementation}
	
		Modern System access their hardware through different channels.
		Which one and how these are used depends on the type of hardware and on the requirements to the system.
		These are often a high bandwidth to transmit data or a low latency to react on input.
		Depending on these demands different mechanisms are used.
		
		Peripheral devices are often connected via busses such as the PCI (Peripheral Component Interconnect).
		Those devices can either be user hardware such as graphics card or controller that connect other bus systems or devices.
		The SATA bus is such an example.
		While hard drive disks are connected directly to it a controller is necessary that connects it to the PCI bus which again is connected to the CPU.
		
		While the amount of different busses is large access to them can be broken down to a few mechanisms.
		Higher level accessors that enable more distant devices such as the drive mentioned in the example can be broken down to these few.
		Orders for the driver on the SATA bus are just an abstraction to what needs to be communicated with the SATA controller. \citep{iosystems}
	
		\section{Integration into Genode}
		The integration into Genode is done by creating a base directory.
		This is used to build a core binary which then is executed by the kernel.
		Since there is already a core that is able to use the Linux kernel it would be redundant to rewrite these parts.
		Reusing the already available code can be done in three different ways.
	
		\subsection{Copy base-linux}
		The simplest way to build upon base-linux is creating a copy it in a new base directory.
		The advantage of this approach lies in the fact that there is, beside including the new directory, no need to modify upstream code.
		On the other hand this leads to code duplication and any updates of base-linux probably need to be ported to its modified copy.
	
		\subsection{Include base-linux}
		Creating a new base directory and including the needed contents from base-linux via Makefile fragments.
		While this would include the advantages of the copy based approach there is less to no code duplication.
		The disadvantage here is the complexity due to the build system that does not provide a standard way to include parts of other base directories.
	
		\subsection{Extend base-linux}
		To prevent both code duplication and complex includes the already existing base directory could be used and extended.
		While this approach seems to be easier it has two caveats.
		Since it requires modifications of the original base-linux core the current functionality needs to be maintained.
		This can be done either by creating a hybrid core that is able to run like the current one and on a bare Linux kernel or a switch needs to be added that chooses the target on build time.
		Additionally this code needs to be brought upstream as it cannot be plugged into the source tree like a separate base directory.
		
		\section{IO Ports}
		
		IO ports or port IO is a mechanism used mainly on the Intel x86 architecture.
		It consists of a hardware bus that is connected directly to the processor and peripheral devices.
		The ports can be used for bidirectional communication similar to a serial interface.
		Access is handled through a specific set of instructions that take addresses and data.
		A special benefit of this mechanism is its atomicity.
		Instructions are guaranteed to be finished before the execution of their successors.
		
		There are 2\textsuperscript{16} addressable ports which transmit 8 bit of data per transaction.
		Consecutive ports can be used to transmit up to 32 bit at once.
		To make use of this the ports need to be aligned on even addresses (for 16 bit transmissions) or on multiples of four (for 32 bit transmissions).
		Other alignments are possible but come with a performance loss.
		
		On modern systems this mechanism often supports legacy hardware such as PS/2 or a floppy disk controllers.
		Also many other architectures lack this type of communication and use memory mapped IO which is also increasingly used with Intel x86 hardware.
		\citep{ioports} \citep{intelmanual}
		
		The implementation of of the \texttt{IO\_Port} session on Linux can be done straight forward.
		This is because IO ports are already available in the user space.
		The only requirement to use them is access to priveledge level 3 which can be achieved with root access on Linux.
		There are several methods that can be used and need to be implemented to use these ports.
		An example are \texttt{unsigned char inb(unsigned short int port)} and \texttt{void outb(unsigned char value, unsigned short int port)} which are used to respectively read and write a single byte to a specific port address.
		To use these functions the permissions need to be granted first.
		This can be done either by \texttt{int iopl(int level)} or \texttt{int ioperm(unsigned long from, unsigned long num, int turn\_on)} which are explained subsequently. \citep{outb} \citep{ioperm} \citep{iopl}
				
		\subsection{iopl}
		
		The first option, \texttt{iopl} grants the calling process a specific privilege level.
		On Linux these levels range from zero to three where zero is the level of a normal process and 3 is the highest one.
		These privileges are also inherited by child processes created by \texttt{fork} or \texttt{execve}. \citep{iopl}
		
		On Genode core would call \texttt{iopl} once it starts and creates the \texttt{IO\_Port} session.
		A component would access these ports through the session interface which also regulates the port ranges.
		
		\subsection{ioperm}
		
		\texttt{ioperm} is a more fine grained option to get the required privileges.
		Instead of \texttt{iopl} it does not give the calling process a higher privilege level but only access to a certain range of IO ports.
		This needs to be specified on the call by passing the starting port and the amount of ports that are accessed consecutively.
		It also does not allow processes to access overlapping port ranges. \citep{ioperm}
		
		The approach on Genode is to call this syscall when a client connects to the \texttt{IO\_Port} session with the required port ranges.
		This would not collide with the checks implemented in Genode but would provide the enforcement of these constraints on kernel level.
		
		\section{Memory mapped IO}
		
		Memory mapped IO is a widely used mechanism to access hardware.
		It maps hardware registers into the physical address space.
		From the view of the operating system it looks as it is part of the available RAM.
		Yet these regions differ in behaviour to conventional registers.
		Accesses to memory mapped IO cannot be cached as they might have side effects on hardware or other registers.
		Even reading might influence the device.
		This is important especially in exception handling where accesses might be repeated.
		
		Memory mapped IO is widely used on different architectures as it provides a clear interface and enables the transfer of substantial amounts of data.
		Also with 64 bit addressing the physical address space is large enough to prevent collisions with conventional RAM.
		\citep{intelmanual}
		
		While memory mapped IO is much more important that IO ports Linux does not provide a good interface to use it from the user space.
		There is already a mechanism to access physical memory ranges from the user space on Linux, \texttt{/dev/mem}.
		This is a special character device that can be used by a user space program to map a physical range of memory into its address space.
		While this would be sufficient to make things "work" it lacks a more fine grained access control.
		
		Any process that is able to open that device and map its memory can access all the available ranges and not only what it is supposed to.
		In newer kernels this has a small restriction that only IO memory can be mapped.
		Before it was even possible to access the whole available memory, even that of the kernel and other processes. \citep{devmem}
		
		Yet the access to only device memory ranges, but all of them, is still insufficient as a driver should only access the ranges its parent allowed it to.
		This leads to the requirement of a more constrainable and controllable access mechanism.
		
		\subsection{Memory device}
		
		The easiest would be using \texttt{/dev/mem} which already has mapped all physical memory into the user space.
		While on early kernel versions it was possible to access the whole memory current versions have the \texttt{CONFIG\_STRICT\_DEVMEM} configuration option enabled which only allows access to IO memory but not arbitrary RAM.
		
		Yet any process that holds a file descriptor can still access all IO ranges and therefore control nearly all hardware devices.
		This cannot be constrained in any way which is a danger to Genodes process isolation.
		While only core is able to open the file descriptor and pass it to a component the component needs to map the memory by itself.
		Since it can map arbitrary regions of memory it would be able to control devices or interfere with other drivers without core having the ability to control or restrict such an action.
		As this strongly violates the security assumptions this option should only be implemented if any other fails. \citep{devmem} 
		
		\subsection{System call}
		
		A more fine grained and better controllable solution would be a custom system call.
		It could be implemented to take the offset and size of the memory region and map it directly into the user space.
		Also Genode specific attributes could be used since there is no constraint in available functionality.
		
		While this is a powerful solution it comes with certain limitations.
		System calls cannot be added by kernel modules and need to be implemented directly inside the kernel.
		This does not only require the the kernel to be compiled for each device but also a manual upgrade each time a new version is released.
		Also a syscall number needs to be chosen that does not collide with any existing one.
		While this sounds easy in the first place it either requires the number registrated by kernel developers to prevent collisions or to reassign it in future versions.
		So beside this being a powerful way to enable user space memory mapping it also requires a higher maintenance over time. \citep{syscall}
		
		\subsection{SysFS}
		
		The Linux \texttt{sysfs} which is located in \texttt{/sys} is a common way to enable communication between user space applications and the kernel.
		This is usually done by accessing files in \texttt{/sys}.
		An implementation of such a driver would provide a file that the arguments are placed into; for example the space separated name, offset and size of the regarded memory region.
		It would then place an correspondingly named device file into ts directory that the user space process can open and map. \citep{sysfs}
		
		As this enables the driver to selectively make memory regions accessible, even to specific users only, this would fit Genodes security model.
		Core would be responsible to set the correct arguments into the input file and the component could open and map the file according to its capabilities.
		
		Yet there are some disadvantages, especially in regards to complexity.
		Mapping a memory region would need multiple file operations.
		Also the direct access to files in \texttt{/sys} is disregarded since the structure of the file system can change.
		To prevent effects of these changes it is recommended to use an abstraction layer such a udev or HAL.
		These dependencies would furthermore increase the complexity of this approach.
		Since Genodes \texttt{base-linux} does not depend yet on sysfs it could be removed from the kernel later.
		That would not be true anymore if this approach was chosen. \citep{sysfs}
		
		\subsection{Fcntl}
		
		Another implementation option is the use of \texttt{fcntl} on a file descriptor of \texttt{/dev/mem}.
		This function is designed to implement custom operation on file descriptor properties such as setting the file status and make the file readable or writeable through this descriptor.
		It is a multiplexing system call that can perform different operations based on its arguments.
		In this case all of these are file specific and custom operations are usually of low complexity or derived from already existing ones.
		Yet it is not clear if the required constraints can be layed upon the file descriptor on \texttt{/dev/mem}. \citep{syscall} \citep{fcntl}
		
		\subsection{Prctl}
		
		Another option, more process than file centered, is \texttt{prctl} which implements custom operations on processes.
		It is similar to \texttt{fcntl} in its nature as a system call multiplexer.
		It implements different operations that manipulate the processes own properties such as thread names.
		Also custom implementations are recommended to be either rather simple or derived from already existing ones.
		The idea is to map a specific part of memory directly into the process.
		However it is questionable if the semantics of mapping memory fit into modifying a processes attributes. \citep{syscall} \citep{prctl}
		
		\subsection{Custom device with ioctl}
		\label{hwio}
		
		While, except for \texttt{sysfs}, most of these options use methods that were not intended to be used that way this is a partially reimplementation of \texttt{/dev/mem} fixing the issues stated above.
		The custom device also makes memory mappable to a process via the file descriptor.
		Yet it supports a custom implemented \texttt{ioctl} that is able to constrain the device accordingly.
		
		While \texttt{ioctl} is similar to \texttt{fcntl} it also supports sending and receiving data to and from the device.
		The data is copied from and to the kernel space accordingly.
		This and the control over the devices implementation allow a constraint to the memory that can be mapped while on the other hand having no dependencies beside \texttt{/dev}.
		It also can be built as a kernel module which makes it loadable at run time. \citep{ioctl}
		
		\section{Interrupts}
		
		Interrupts are asynchronous events sent by external devices.
		Beside the so called interrupt number no further information is transmitted.
		Also this is a single directional channel.
		Interrupts are triggered by a device and received by the CPU.
		
		When an interrupt occurs the execution of the current task is interrupted by the CPU and a handler procedure is called.
		The handler is registered to one of the 18 predefined or 224 user defined interrupts.
		When it is called the only information available is that one of the interrupts it was registered to has been triggered.
		Any further information needs to be acquired through other channels, for example memory mapped IO. \citep{intelmanual}
		
		This mechanism is usually used for devices that wait for events such as keyboards.
		Instead of checking periodically if a key has been pressed it registers an interrupt that is triggered once a key is pressed.
		Then the driver can check which key has been pressed and pass this information to the operating system.
		
		The Linux kernel does not allow to register an interrupt handler in the user space.
		It is possible to see and observer interrupts in \texttt{/proc/interrupts} yet polling them from this file is not feasible as they are often require a low latency.
		This leads to the need of a new mechanism that provides user space access and a reasonable latency.
		
		On Genode interrupts are implemented as threads that wait for a given hardware interrupt.
		Once it is triggered the thread is woken up and calls the interrupt handler.
		It is also masked and cannot receive further hardware interrupts until the handler acknowledged the handling of the last one. \citep{genode}
		
		With this behaviour in mind the interrupt on Linux can be implemented as a blocking read on a special device file.
		The generic way is similar to the one described in section \ref{hwio}.
		A custom device is opened and the file descriptor is configured via \texttt{ioctl}.
		The configuration would set the interrupt number that the handler should be tied to.
		Inside the module it would register on the according interrupt of the Linux kernel.
		
		The interrupt thread in Genode would receive the configured file descriptor and call a read on it.
		The device has implemented the read in such a way that it will not return until the interrupt is triggered inside the kernel.
		Once this happened the read would return and the handling can go on as defined in Genode.
		
		The masking of the interrupt is done by not calling read which.
		This results in ignoring all hardware interrupt that occur in this time.
		An acknowledgement by the handler calls read again and therefore unmasks the interrupt.
		
		This solution implements interrupts on Linux without polling and therefore should gain a feasible latency.
		It also keeps the correct semantics of the implementation in Genode and should not require any workarounds.
		
		\section{Complexity}
		
		With security assumptions in mind enabling resource access for the user space is not the only requirement.
		The Linux kernel is a complex construct with millions of lines of code.
		To reduce this complexity as much unnecessary functionality as possible needs to be removed.
		Beside the removal of drivers that are provided by the user space system such as USB and graphics support also other subsystems that usually are not directly visible to the common user need to be taken care of.
		
		This is especially important for parts that could be used to implement other requirements.
		So it needs to be taken care of that nothing depends on those.
		These systems include \texttt{procfs} and \texttt{sysfs} which many user space interfacing drivers depend on. \citep{sysfs} \citep{procfs}
		
		Also some drivers are required to be removed not only because of complexity but their interference with drivers that should run in the user space.
		While the kernel might even allow multiple entities to access the same range of memory or IO ports this will likely cause errors.
		Since these mechanisms access hardware resources they are highly volatile which also means that changes made by one driver are visible in another accessing the same device.
		To prevent this any resource that is used by a user space driver must not be used by the kernel.
		
		

	
	
	\chapter{Evaluation}

	
	\bibliographystyle{unsrtnat}
	\bibliography{sources}
	
\end{document}

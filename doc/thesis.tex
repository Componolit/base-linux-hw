\documentclass[
a4paper,
12pt,
notitlepage,
parskip=half,
DIV=11,
]{scrbook}

\usepackage[english,ngerman]{babel}
\usepackage[utf8]{inputenx}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{graphicx}

\usepackage[numbers]{natbib}
\usepackage{cite}

\input{genode-manual/manual/img/tikz-preamble.tex}
\input{genode-manual/manual/img/tikz-common.tex}

\begin{document}
	
	\selectlanguage{english}
	\tableofcontents
	
	\chapter{Introduction}
	
	At the present time we are surrounded by devices that run complex software and operating systems.
	The number of these devices is still rising and their complexity is growing by the increasing amount computational resources, functionalities and interfaces.
	Also many of these devices are taking over important tasks such as smart locks or even cardiac pacemakers.
	Since most of these devices are connected to the public Internet they cannot only be accessed by their owners but anyone.
	
	These facts raise the question if we can trust these devices.
	Many cases in the present have shown that nearly all of these devices have security issues.
	Since the used systems are too complex to guarantee the absence of software errors the common practice is patching these devices when an error has been discovered.
	Unfortunately the approach of fixing errors has not proven reliable.
	Updates are often not or only for a short time available and often do not find their way to the end user.
	
	A difference to this practice are sectors where manufacturers are liable for the correctness of their products including software parts.
	This can be achieved by enforcing specific work flows that reduce error probabilities and intensive testing.
	But also verification with formal and mathematical methods can be used diminish the rate of faults.
	
	While this seems to be a solution to the current problems this approach is far from being scalable enough.
	Comprehensive testing requires a high amount of resources that often is not available or economically reasonable.
	Also verification requires an even higher effort and for many large projects it is far from being possible.
	This leads to the question how the high complexity of current applications can be combined with the trustiness of comprehensively tested and verified software.
	
	That is the point where component based systems have their use case.
	They separate the untrusted parts of the software from each other while providing defined ways for them to communicate with each other.
	The component based system itself does not implement any functionality beside separation and enforcement of policies.
	This allows a small trusted code base that is able to be verified and tested.
	
	The software components themselves do not need to be trusted any more.
	Due to the separation a fault or security issue does only affect a single component and cannot spread across other applications.
	To enforce this behaviour through all parts of the system the architecture is based on a micro kernel.
	
	Most of the common operating systems use a monolithic kernel.
	This means that all drivers run in the kernel space.
	Not only hardware accessing parts are included there but also file systems and networking stacks.
	This leads to the problem that if only one of these drivers is compromised it can access the whole kernel and therefore the complete system.
	All security assumptions in the user space are invalid from this point.
	
	Micro kernels solve this problem by implementing only the most basic hardware access mechanisms.
	This keeps their code base small and verifiable.
	On the other hand drivers run in the user space and profit from the security advantages brought along by the component based system.
	
	\chapter{Background} %hardware description

	Modern System access their hardware through different channels.
	Which one and how these are used depends on the type of hardware and on the requirements to the system.
	These are often a high bandwidth to transmit data or a low latency to react on input.
	Depending on these demands different mechanisms are used.
	
	Peripheral devices are often connected via busses such as the PCI (Peripheral Component Interconnect).
	Those devices can either be user hardware such as graphics card or controller that connect other bus systems or devices.
	The SATA bus is such an example.
	While hard drive disks are connected directly to it a controller is necessary that connects it to the PCI bus which again is connected to the CPU.
	
	While the amount of different busses is large access to them can be broken down to a few mechanisms.
	Higher level accessors that enable more distant devices such as the drive mentioned in the example can be broken down to these few.
	Orders for the driver on the SATA bus are just an abstraction to what needs to be communicated with the SATA controller. \citep{iosystems}

	\section{IO Ports}
	
	IO ports or port IO is a mechanism used mainly on the Intel x86 architecture.
	It consists of a hardware bus that is connected directly to the processor and peripheral devices.
	The ports can be used for bidirectional communication similar to a serial interface.
	Access is handled through a specific set of instructions that take addresses and data.
	A special benefit of this mechanism is its atomicity.
	Instructions are guaranteed to be finished before the execution of their successors.
	
	There are 2\textsuperscript{16} addressable ports which transmit 8 bit of data per transaction.
	Consecutive ports can be used to transmit up to 32 bit at once.
	To make use of this the ports need to be aligned on even addresses (for 16 bit transmissions) or on multiples of four (for 32 bit transmissions).
	Other alignments are possible but come with a performance loss.
	
	On modern systems this mechanism often supports legacy hardware such as PS/2 or a floppy disk controllers.
	Also many other architectures lack this type of communication and use memory mapped IO which is also increasingly used with Intel x86 hardware.
	\citep{ioports} \citep{intelmanual}
	
	\section{Memory mapped IO}
	
	Memory mapped IO is a widely used mechanism to access hardware.
	It maps hardware registers into the physical address space.
	From the view of the operating system it looks as it is part of the available RAM.
	Yet these regions differ in behaviour to conventional registers.
	Accesses to memory mapped IO cannot be cached as they might have side effects on hardware or other registers.
	Even reading might influence the device.
	This is important especially in exception handling where accesses might be repeated.
	
	Memory mapped IO is widely used on different architectures as it provides a clear interface and enables the transfer of substantial amounts of data.
	Also with 64 bit addressing the physical address space is large enough to prevent collisions with conventional RAM.
	\citep{intelmanual}
	
	\section{Interrupts}
	
	Interrupts are asynchronous events sent by external devices.
	Beside the so called interrupt number no further information is transmitted.
	Also this is a single directional channel.
	Interrupts are triggered by a device and received by the CPU.
	
	When an interrupt occurs the execution of the current task is interrupted by the CPU and a handler procedure is called.
	The handler is registered to one of the 18 predefined or 224 user defined interrupts.
	When it is called the only information available is that one of the interrupts it was registered to has been triggered.
	Any further information needs to be acquired through other channels, for example memory mapped IO. \citep{intelmanual}
	
	This mechanism is usually used for devices that wait for events such as keyboards.
	Instead of checking periodically if a key has been pressed it registers an interrupt that is triggered once a key is pressed.
	Then the driver can check which key has been pressed and pass this information to the operating system.
	
	\chapter{State of the art}
		
		\section{Genode}
		
		Genode aims to solve this problem through multiple ways.
		Instead of a monolithic kernel it uses microkernels.
		They provide a greater flexibility than separation kernels why keeping the size of the trusted computing base at a manageable level.
		This is accomplished for example by running device drivers as separate user space processes.
		User space applications in Genode are also managed by capabilities.
		They provide a way to allow and deny access to a certain number of system resources without the need for a global complex policy.
		Additionally to capabilities resources can be managed in a hierarchical way.
		Software components can be be partitioned into parts of different complexity.
		This helps to exclude complex parts from the trusted computing base and therefore reduce the amount of code that needs to be verified.
		The continuation of this approach leads to an application specific trusted computing base that consists of the application itself and all the parts it depends on [\ref{fig:tcb_tree}].
		\citep{genode}
		
		\begin{figure}
			\centering
			\input{genode-manual/manual/img/app_specific_tcb.tikz}
			\caption{Application based TCB \citep{genode}}
			\label{fig:tcb_tree}
		\end{figure}
	
		The Genode OS framework is the implementation of this architecture for highly secure special purpose operating systems.
		Mainly written in C++ it scales from embedded systems with only a few megabytes of memory to big systems with dynamic workloads.
		The architecture consists of a recursive sandbox structure.
		Those are controlled from their parents and separated from their siblings.
		But they can create additional sandboxes and subtrees of children.
		This creates hierarchical structures and reduces the attack surface of the system since a compromised component cannot access resources of other components.
		These components are small blocks that can create complex systems without unnecessarily increasing the trusted computing base.
		Beside being programs they can also provide other functionalities such as device drivers or protocol stacks.
		
		Genode supports multiple CPU architectures such as Intel i386 and ARM.
		Multiple microkernels such as NOVA and seL4 can be used.
		Additionally Genode provides a custom kernel implementation that in comparison to other kernels further reduces the trusted computing base.
		The current framework also provides many usable driver and application components.
		Beside common periphery drivers such as USB and Intel wireless this also includes complex application frameworks such as Qt5. \citep{genode}
		
		To debug components in the development process Genode can also be started on the current running Linux kernel.
		This is a good approach for applications but is also limited.
		Some resources cannot be used since the Linux kernel doesn't provide them to the user space, for example memory mapped IO or direct memory access.
		To develop and debug native Genode device drivers the kernel needs to act as a microkernel and provide access to these resources in Genode.
		
		\section{User space drivers on Linux}
		
		There have already been different approaches on using suer space drivers on Linux.
		A, in the Linux world widely known, project is Filesystem in Userspace (FUSE).
		It's target is to provide users with the ability to use custom file systems without the need to require root privileges or edit kernel code.
		To achieve this FUSE consists of two parts, a kernel module and a user space library.
		The library communicates with the kernel module to provide the necessary functionality to the user.
		While this does not access any hardware resources it shows a concept how kernel resources can be accessed from the user space. \citep{fuse}
		
		Another approach is Userspace I/O (UIO).
		UIO addresses industrial systems that often require I/O cards which only need some mapped memory and interrupts.
		These cards are available as device files on Linux which provide access to the address space of each device.
		Contrary to FUSE UIO drivers require a small kernel module that deploys access to hardware resources.
		But the driver logic can be implemented in user space.
		This gives a number of advantages for both the programmer and the user.
		Instead of kernel modules these drivers can use many tools and libraries that are not available in the kernel.
		Also bugs and crashes of the driver do not influence the kernel itself.
		While updates of kernel modules often require the recompilation of the kernel or at least a reboot of the system updates of these drivers can be done more easily. \citep{uio}
		
		\section{Rump kernels}
		A rump kernel provides a lightweight environment for drivers on top of an anykernel.
		The flexible anykernel architecture allows kernels to run in different configurations or modes.
		They can be created from a monolithic kernel with a moderate effort.
		While they provide an interface for rump based drivers they also preserve their monolithic properties and driver stacks. \citep{kantee}
		
		Drivers on top of a rump kernel only need to interface with it and not the underlying kernel.
		That makes this concept portable to highly different platforms such as monolithic or micro kernels.
		This is achieved by stripping away all unneeded components of a kernel and only leaving those required for drivers to work.
		At the lower part of the kernel exists a small and well defined portability layer to interface with the underlying environment.
		These concepts were implemented first by the NetBSD project. \citep{bsd_rump}\citep{fosdem_rump}\citep{rump}
		
		Rump applications and drivers are created using the so called Hypercall API.
		There are two main parts of this API.
		The first one are basic calls for applications such as those for allocating memory or using threads.
		The second is about handling I/O operations and is splitted into a virtual and a physical part.
		The virtualized calls access services provided by the host operating system such as network interfaces and protocols. \citep{rump_man} \citep{rump_platform}
		
		While system calls and access to the host systems interfaces is defined straightforward direct hardware access is not.
		With one exception the rump kernel does not have support to directly map physical memory.
		These mappings are usually represented as files on the host system.
		While these files could be used to map memory into the rump kernel they would also limit the platforms and environments where it can be hosted.
		The only exception to this are vnodes which are inode representations in memory.
		The approach of the rump kernel to solve this problem is to allocate a block of memory and copy the contents of the memory mapped by the host system back and forth.
		This works only because the vnode pages can be accessed by a single consumer at a time.
		Therefore this approach is inapplicable for memory mapped IO or volatile memory. \citep{kantee}
		
		Another important aspect of hardware drivers are interrupts.
		Hardware interrupts usually preempt the CPU which is not supported by the rump kernel.
		Instead they are implemented as host threads which then schedule the handler inside the rump kernel accordingly. \citep{kantee}
		
		While these properties speak against hardware drivers in the first place there is one example of a hardware device driver for USB devices described.
		Yet this example operates on a higher level than direct access to hardware resources.
		The BSD kernel makes USB devices accessible to the user space via \texttt{ugen} the USB generic device support.
		The rump kernel implementation of the USB driver allows to configure the access to specific USB devices at compile time. \citep{kantee} \citep{ugen}
		
	\chapter{Requirements} %%what needs to be done
	
	\section{IO Ports}
	
	\section{Memory mapped IO}
	
	\section{Interrupts}
	
	
	\chapter{Design}
	
		\section{Integration into Genode}
		The integration into Genode is done by creating a base directory.
		This is used to build a core binary which then is executed by the kernel.
		Since there is already a core that is able to use the Linux kernel it would be redundant to rewrite these parts.
		Reusing the already available code can be done in three different ways.
	
		\subsection{Copy base-linux}
		The simplest way to build upon base-linux is creating a copy it in a new base directory.
		The advantage of this approach lies in the fact that there is, beside including the new directory, no need to modify upstream code.
		On the other hand this leads to code duplication and any updates of base-linux probably need to be ported to its modified copy.
	
		\subsection{Include base-linux}
		Creating a new base directory and including the needed contents from base-linux via Makefile fragments.
		While this would include the advantages of the copy based approach there is less to no code duplication.
		The disadvantage here is the complexity due to the build system that does not provide a standard way to include parts of other base directories.
	
		\subsection{Extend base-linux}
		To prevent both code duplication and complex includes the already existing base directory could be used and extended.
		While this approach seems to be easier it has two caveats.
		Since it requires modifications of the original base-linux core the current functionality needs to be maintained.
		This can be done either by creating a hybrid core that is able to run like the current one and on a bare Linux kernel or a switch needs to be added that chooses the target on build time.
		Additionally this code needs to be brought upstream as it cannot be plugged into the source tree like a separate base directory.
		
		\section{IO Ports}
		
		The implementation of of the \texttt{IO\_Port} session on Linux can be done straight forward.
		This is because IO ports are already available in the user space.
		The only requirement to use them is access to priveledge level 3 which can be achieved with root access on Linux.
		There are several methods that can be used and need to be implemented to use these ports.
		An example are \texttt{unsigned char inb(unsigned short int port)} and \texttt{void outb(unsigned char value, unsigned short int port)} which are used to respectively read and write a single byte to a specific port address.
		To use these functions the permissions need to be granted first.
		This can be done either by \texttt{int iopl(int level)} or \texttt{int ioperm(unsigned long from, unsigned long num, int turn\_on)} which are explained subsequently. \citep{outb} \citep{ioperm} \citep{iopl}
				
		\subsection{iopl}
		
		The first option, \texttt{iopl} grants the calling process a specific privilege level.
		On Linux these levels range from zero to three where zero is the level of a normal process and 3 is the highest one.
		These privileges are also inherited by child processes created by \texttt{fork} or \texttt{execve}. \citep{iopl}
		
		On Genode core would call \texttt{iopl} once it starts and creates the \texttt{IO\_Port} session.
		A component would access these ports through the session interface which also regulates the port ranges.
		
		\subsection{ioperm}
		
		\texttt{ioperm} is a more fine grained option to get the required privileges.
		Instead of \texttt{iopl} it does not give the calling process a higher privilege level but only access to a certain range of IO ports.
		This needs to be specified on the call by passing the starting port and the amount of ports that are accessed consecutively.
		It also does not allow processes to access overlapping port ranges. \citep{ioperm}
		
		The approach on Genode is to call this syscall when a client connects to the \texttt{IO\_Port} session with the required port ranges.
		This would not collide with the checks implemented in Genode but would provide the enforcement of these constraints on kernel level.
		
		\section{Memory mapped IO}
		
		While memory mapped IO is much more important that IO ports Linux does not provide a good interface to use it from the user space.
		It only has a \texttt{mem} device that has all physical memory mapped into a file.
		while this is an easy method to map memory into a user space process it has some disadvantages especially in regard to Genodes security and process isolation.
		If those disadvantages shall be avoided a custom adoption of kernel space needs to be done.
		This goal can be achieved in multiple ways.
		
		Also while there are multiple already existing solutions to write user space drivers these usually either pull dependencies behind or are too complex for the goal of a minimized kernel.
		
		\subsection{Memory device}
		
		The easiest would be using \texttt{/dev/mem} which already has mapped all physical memory into the user space.
		While on early kernel versions it was possible to access the whole memory current versions have the \texttt{CONFIG\_STRICT\_DEVMEM} configuration option enabled which only allows access to IO memory but not arbitrary RAM.
		
		Yet any process that holds a file descriptor can still access all IO ranges and therefore control nearly all hardware devices.
		This cannot be constrained in any way which is a danger to Genodes process isolation.
		While only core is able to open the file descriptor and pass it to a component the component needs to map the memory by itself.
		Since it can map arbitrary regions of memory it would be able to control devices or interfere with other drivers without core having the ability to control or restrict such an action.
		As this strongly violates the security assumptions this option should only be implemented if any other fails. \citep{devmem} 
		
		\subsection{System call}
		
		A more fine grained and better controllable solution would be a custom system call.
		It could be implemented to take the offset and size of the memory region and map it directly into the user space.
		Also Genode specific attributes could be used since there is no constraint in available functionality.
		
		While this is a powerful solution it comes with certain limitations.
		System calls cannot be added by kernel modules and need to be implemented directly inside the kernel.
		This does not only require the the kernel to be compiled for each device but also a manual upgrade each time a new version is released.
		Also a syscall number needs to be chosen that does not collide with any existing one.
		While this sounds easy in the first place it either requires the number registrated by kernel developers to prevent collisions or to reassign it in future versions.
		So beside this being a powerful way to enable user space memory mapping it also requires a higher maintenance over time. \citep{syscall}
		
		\subsection{SysFS}
		
		The Linux \texttt{sysfs} which is located in \texttt{/sys} is a common way to enable communication between user space applications and the kernel.
		This is usually done by accessing files in \texttt{/sys}.
		An implementation of such a driver would provide a file that the arguments are placed into; for example the space separated name, offset and size of the regarded memory region.
		It would then place an correspondingly named device file into ts directory that the user space process can open and map. \citep{sysfs}
		
		As this enables the driver to selectively make memory regions accessible, even to specific users only, this would fit Genodes security model.
		Core would be responsible to set the correct arguments into the input file and the component could open and map the file according to its capabilities.
		
		Yet there are some disadvantages, especially in regards to complexity.
		Mapping a memory region would need multiple file operations.
		Also the direct access to files in \texttt{/sys} is disregarded since the structure of the file system can change.
		To prevent effects of these changes it is recommended to use an abstraction layer such a udev or HAL.
		These dependencies would furthermore increase the complexity of this approach.
		Since Genodes \texttt{base-linux} does not depend yet on sysfs it could be removed from the kernel later.
		That would not be true anymore if this approach was chosen. \citep{sysfs}
		
		\subsection{Fcntl}
		
		Another implementation option is the use of \texttt{fcntl} on a file descriptor of \texttt{/dev/mem}.
		This function is designed to implement custom operation on file descriptor properties such as setting the file status and make the file readable or writeable through this descriptor.
		It is a multiplexing system call that can perform different operations based on its arguments.
		In this case all of these are file specific and custom operations are usually of low complexity or derived from already existing ones.
		Yet it is not clear if the required constraints can be layed upon the file descriptor on \texttt{/dev/mem}. \citep{syscall} \citep{fcntl}
		
		\subsection{Prctl}
		
		Another option, more process than file centered, is \texttt{prctl} which implements custom operations on processes.
		It is similar to \texttt{fcntl} in its nature as a system call multiplexer.
		It implements different operations that manipulate the processes own properties such as thread names.
		Also custom implementations are recommended to be either rather simple or derived from already existing ones.
		The idea is to map a specific part of memory directly into the process.
		However it is questionable if the semantics of mapping memory fit into modifying a processes attributes. \citep{syscall} \citep{prctl}
		
		\subsection{Custom device with ioctl}
		
		While, except for \texttt{sysfs}, most of these options use methods that were not intended to be used that way this is a partially reimplementation of \texttt{/dev/mem} fixing the issues stated above.
		The custom device also makes memory mappable to a process via the file descriptor.
		Yet it supports a custom implemented \texttt{ioctl} that is able to constrain the device accordingly.
		
		While \texttt{ioctl} is similar to \texttt{fcntl} it also supports sending and receiving data to and from the device.
		The data is copied from and to the kernel space accordingly.
		This and the control over the devices implementation allow a constraint to the memory that can be mapped while on the other hand having no dependencies beside \texttt{/dev}.
		It also can be built as a kernel module which makes it loadable at run time. \citep{ioctl}
		
		\section{Interrupts}
		
		
	\chapter{Implementation}
	
	\section{IO Ports}
	
	\section{Memory mapped IO}
	
	
	\chapter{Evaluation}
	\chapter{Conclusion}
	
	\bibliographystyle{unsrtnat}
	\bibliography{sources}
	
\end{document}
\documentclass[
a4paper,
12pt,
notitlepage,
parskip=half,
DIV=11,
]{scrbook}

\usepackage[utf8]{inputenx}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{graphicx}

\usepackage[numbers]{natbib}
\usepackage{cite}

\input{genode-manual/manual/img/tikz-preamble.tex}
\input{genode-manual/manual/img/tikz-common.tex}

\begin{document}
	
	\tableofcontents
	
	\chapter{Introduction}
		
	
        At the present time we are surrounded by devices that run complex software and operating systems.
		The number of these devices is still rising and their complexity is growing by the increasing amount computational resources, functionalities and interfaces.
		Also many of these devices are taking over important tasks such as smart locks or even cardiac pacemakers.
		Since most of these devices are connected to the public Internet they cannot only be accessed by their owners but anyone.
		
		Most of the modern systems run on kernels built in a monolithic manner.
		This implies that a high amount of the critical functionality such as device drivers and networking stack are implemented by them.
		All these complex software constructs run on the so called kernel mode which is the highest privileged mode it can achieve.
		It is where the operating system kernel usually runs in.
		Since it can access and control the whole system including any user processes a single vulnerability in any of its components could compromise the entire system.
		
		Furthermore the quality of this software is often bad.
		This is especially true for device drivers which have, according to \citep{Chou:SOSP:01},  around three to seven times higher error rates than other kernel parts.
		That is even more problematic since drivers also are the majority of the code.
		While an attacker often needs to find only a single error monolithic kernels often contain thousands of them due to their large code base.
		
		Also when bugs appear in the kernel it needs in average far over one year until a fix is available.
		And even then it takes additional time until it is brought to the user.
		There are also systems that cannot be patched for different reasons.
		These will stay vulnerable for their whole lifetime. \citep{Chou:SOSP:01}
		
		A first step to mitigate this problem would be the usage of user level drivers.
		The user level is a less privileged mode than the kernel mode.
		It runs most of the software on a system including all conventional end user applications.
		Also while the kernel is able to access any resource like physical memory a process running in the user mode cannot.
		It is limited to its own address range in memory and can access other resources only through the kernel.
		This would not solve the problems based on the errors in the software itself but it would lower their privileges.
		A compromised driver would not be able to access and control the whole system but only a part of it.
		
		Unfortunately user space drivers on Linux are quite uncommon.
		While some approaches exist, such as FUSE \citep{fuse} or Userspace IO (UIO) \citep{uio} they are still limited.
		UIO for example requires a loadable kernel module for each driver which still adds complexity to the kernel instead of taking it away.
		FUSE only implements file system drivers and does not have access to any hardware resources.
		
		A solution to this problem are micro kernels.
		They implement only the minimally required functionality inside the kernel which reduces their complexity.
		This includes the management of memory and hardware access.
		They do not implement drivers which are responsible for a high amount of the complexity and errors in monolithic systems. \citep{Chou:SOSP:01}
		
		Based on micro kernels drivers are implemented in the user space.
		This lowers their privileges and isolates them from each other.
		The Genode OS Framework is an implementation of this concept. 
		It is a component based system that runs on different micro kernels such as NOVA or seL4.
		It realizes a strict separation of its components and only allows a defined communication between them.
		
		On the other hand micro kernels often do not support less used or exotic platforms.
		Porting them to a new unsupported platform requires a high effort and needs time.
		Linux however often supports them well and is the only choice for some of them.
		It also comes with good debugging facilities which is an important part for driver development.
		
		The goal of this thesis is the combination of the advantages of both Linux and Genode.
		While it already runs on Linux there is no support for hardware access and device drivers yet.
		Even though Linux is highly complex stripping away its kernel drivers and run them through Genode in the user space increases security while still keeping the good platform support.
		
	\chapter{Background}

		\section{Monolithic kernels}
		
		The kernel is an operating systems most crucial part.
		It controls access to the hardware and manages resources.
		Since it runs with the highest privileges the whole systems security depends on it.
		Most of the widely used operating systems rely on so called monolithic kernels.
		Well known examples are Linux and Microsoft Windows.
		
		A monolithic kernel implements many drivers and subsystems in the kernel space.
		This extensive functionality introduces a high complexity with, in the case of Linux, multiple millions lines of code \citep{journals/jss/IsraeliF10}.
		The whole code is compiled into a single binary that runs in one address space.
		Within this there exists no isolation between subsystems.
		On one hand this introduces a good performance.
		A complex data structure for example can be passed between subsystems by only sharing the pointer to it.
		On the other this introduces vulnerabilities since a single compromised subsystem can access anything else in the kernel.
		
		An example for this is a vulnerability in a Synaptics touchscreen driver.
		It leads to a full compromise of the whole kernel by allowing code execution in the kernel space.
		The result is a full lose of system integrity and confidentiality since the attacker is able to read or modify any part of the operating system. \citep{cve-2017-0581}
		
		Figure \ref{kernelvs} shows the large complexity that monolithic kernels incorporate.
		Anything in the orange marked area is running inside the kernel and therefore in a single address space with no isolation.
		This also counts for loadable kernel modules.
		In contrast to their naming they are not modularized from the kernel.
		They run in the same address space and have the same privileges as the rest of the kernel.
		This is even more critical since they can be proprietary.
		
		To interface with the user space a monolithic kernel uses so called syscalls.
		These are defined procedures that can be called from the user space to do certain tasks that require the kernel.
		When a system call is used, its parameters are put on the stack and a so called trap is executed.
		This triggers a mode switch into the kernel space where the arguments are taken from the stack and the according operation is executed. \citep{Tanenbaum2001}
		
		Yet due to the high amount of functionality there are plenty of system calls.
		The Linux kernel counts, depending on the version, between 350 \citep{journals/jss/IsraeliF10} and nearly 400 \citep{syscalls} of them.
		This introduces a high complexity and a large attack surface.
		
		
		\begin{figure}
			\centering
			\def\svgwidth{\textwidth}
			\input{kernel.pdf_tex}
			\caption{Comparison: monolithic and micro kernel}
			\label{kernelvs}    
		\end{figure}
		
		\section{Microkernels}
		
		Micro kernels are the contrary concept to monolithic kernel.
		Their goal is, in simple terms, to remove as much functionality as possible from the kernel and implement it outside of it.
		This aims to make the system highly modularizable and isolate failures in components from the rest of the system.
		
		As a general requirement a micro kernel should only functionality that would be impossible to implement outside the kernel.
		It also has to separate and protect applications from itself and each other.
		Any component that runs on a micro kernel must not be influenced by any other. And if two components communicate between each other the communication must be secure in regards of confidentiality and integrity.
		
		These requirements are met by different concepts.
		One of them are address spaces which are mappings from physical to virtual memory pages.
		These are given recursively to child subsystems.
		The first subsystem owns the whole physical memory in a single address space from where it can grant parts of it to another subsystem.
		Its own access to this page is then removed.
		If it wants to keep this space, for example to employ shared memory, it can map the space to the other subsystem.
		To reverse the mapping the according address space can be flushed removing it from all other subsystems except the flushing one.
		The managing of these operations is done in the kernel itself.
		While I/O memory is a does not necessarily represent physical main memory it is also managed in this context.
		
		%threads...
		The activity that happens in such an address space is called a thread.
		It is characterized through its own state including its address space, stack pointer and instruction pointer.
		Any changes the thread applies to its address space are controlled by the kernel.
		Also it cannot access address spaces of other threads.
		To be able to communicate inter process communication is used and therefore must be supported by the kernel.
		
		Inter process communication (IPC) is a defined way for two threads to communicate with each other.
		While both parties must agree to the transmission the sender controls the content while the receiver has to handle it.
		This handling includes if the contents are used at all and how they are interpreted.
		
		Beside message based IPC remote procedure calls can be used for communication.
		It does not send data to other threads but migrates the sending one to another address space.
		Both of these communication concepts need to be supervised by the kernel.
		
		On modern hardware interrupts are an often used way of devices to notify the software of events.
		This mechanism also needs to be supported on micro kernels.
		Interrupts are incorporated by empty IPC messages.
		They are sent from threads that have special ids which map to hardware interrupt ids.
		The receiving thread can conclude to the triggered interrupt by the source id. \citep{Liedtke_1995}
		
		\section{Genode}
		
		Genode aims to solve this problem through multiple ways.
		Instead of a monolithic kernel it uses microkernels.
		They provide a greater flexibility than separation kernels why keeping the size of the trusted computing base at a manageable level.
		This is accomplished for example by running device drivers as separate user space processes.
		User space applications in Genode are also managed by capabilities.
		They provide a way to allow and deny access to a certain number of system resources without the need for a global complex policy.
		Additionally to capabilities resources can be managed in a hierarchical way.
		Software components can be be partitioned into parts of different complexity.
		This helps to exclude complex parts from the trusted computing base and therefore reduce the amount of code that needs to be verified.
		The continuation of this approach leads to an application specific trusted computing base that consists of the application itself and all the parts it depends on [\ref{fig:tcb_tree}].
		\citep{genode}
		
		\begin{figure}
			\centering
			\input{genode-manual/manual/img/app_specific_tcb.tikz}
			\caption{Application based TCB \citep{genode}}
			\label{fig:tcb_tree}
		\end{figure}
		
		The Genode OS framework is the implementation of this architecture for highly secure special purpose operating systems.
		Mainly written in C++ it scales from embedded systems with only a few megabytes of memory to big systems with dynamic workloads.
		The architecture consists of a recursive sandbox structure.
		Those are controlled from their parents and separated from their siblings.
		But they can create additional sandboxes and subtrees of children.
		This creates hierarchical structures and reduces the attack surface of the system since a compromised component cannot access resources of other components.
		These components are small blocks that can create complex systems without unnecessarily increasing the trusted computing base.
		Beside being programs they can also provide other functionalities such as device drivers or protocol stacks.
		
		Genode supports multiple CPU architectures such as Intel i386 and ARM.
		Multiple microkernels such as NOVA and seL4 can be used.
		Additionally Genode provides a custom kernel implementation that in comparison to other kernels further reduces the trusted computing base.
		The current framework also provides many usable driver and application components.
		Beside common periphery drivers such as USB and Intel wireless this also includes complex application frameworks such as Qt5. \citep{genode}
		
		To debug components in the development process Genode can also be started on the current running Linux kernel.
		This is a good approach for applications but is also limited.
		Some resources cannot be used since the Linux kernel doesn't provide them to the user space, for example memory mapped IO or direct memory access.
		To develop and debug native Genode device drivers the kernel needs to act as a microkernel and provide access to these resources in Genode.
		
		Some of Genodes properties are important for the evaluation of this thesis and will be explained further.
		One is the source code management which is based on so called repositories that can include multiple sets of software components.
		The other is the session concept which implements the IPC mechanism and also provides abstractions to platform specific code.
		
		\subsection{Repositories}
		\label{repos}
		
		The source code of Genode is organized in so called repositories.
		Each repository, or short repo, can contain multiple software components.
		Itself is divided into different directories.
		The \texttt{src} directory contains all the source code that is built by the build system.
		Together with \texttt{lib} which includes descriptions for the build system on how to build libraries and what interfaces should be publicly visible to other components those are the two most important parts as they are required to build basic components.
		
		\texttt{run} contains so called run files.
		These are complex setups that describe the entire build process for the creation of a complete system.
		The set the required components to build and include into the image and define a configuration.
		This is the heart of a Genode system.
		It defines the allowed resources and IPC routes which are enforced by the core.
		
		Other often used parts are \texttt{doc} which contains documentation and \texttt{etc} that sets specific properties to this repository.
		These define on which architectures or platforms the components of this repository are supported.
		\texttt{tool} contains arbitrary helper objects such as pre built binaries.
		
		The repositories itself can be divided into two main groups.
		Most of them incorporate application level components or device drivers.
		But a few of them, prefixed with \texttt{base}, implement the core component which provides the basic resources and is the direct or indirect parent of all others.
		Since it is platform dependent there exist multiple of these implementations named \texttt{base-<platform>}. \citep{genode}
		
		\subsection{Sessions}
		\label{sessions}
		
		Sessions are the IPC implementation in Genode.
		They provide a way to communicate between components but also an abstraction for platform dependent concepts.
		They are divided into two groups of them, one for the core tasks and one for the operating system level.
		
		The core session include basic resources such as protection domains, RAM and CPU.
		More important for this thesis they also provide hardware access abstractions for I/O memory, I/O ports and interrupts.
		Since logging is an important part of every system it is also included here.
		
		All of them are provided by the core component.
		As the implementation of this group is often not or hardly portable each platform requires its own adaptions.
		They are implemented in the base repositories as described in section \ref{repos}.
		
		The operating system level sessions are mostly platform independent and only rely on the abstractions made by the core component.
		They provide functionality such as framebuffers, network interface cards, timers or file systems. \citep{genode}
	
	\chapter{Related work}
		
		\section{User space drivers on Linux}
		
		There have already been different approaches on using suer space drivers on Linux.
		A, in the Linux world widely known, project is Filesystem in Userspace (FUSE).
		It's target is to provide users with the ability to use custom file systems without the need to require root privileges or edit kernel code.
		To achieve this FUSE consists of two parts, a kernel module and a user space library.
		The library communicates with the kernel module to provide the necessary functionality to the user.
		While this does not access any hardware resources it shows a concept how kernel resources can be accessed from the user space. \citep{fuse}
		
		Another approach is Userspace I/O (UIO).
		UIO addresses industrial systems that often require I/O cards which only need some mapped memory and interrupts.
		These cards are available as device files on Linux which provide access to the address space of each device.
		Contrary to FUSE UIO drivers require a small kernel module that deploys access to hardware resources.
		But the driver logic can be implemented in user space.
		This gives a number of advantages for both the programmer and the user.
		Instead of kernel modules these drivers can use many tools and libraries that are not available in the kernel.
		Also bugs and crashes of the driver do not influence the kernel itself.
		While updates of kernel modules often require the recompilation of the kernel or at least a reboot of the system updates of these drivers can be done more easily. \citep{uio}
		
		\section{Rump kernels}
		
		A rump kernel provides a lightweight environment for drivers on top of an anykernel.
		The flexible anykernel architecture allows kernels to run in different configurations or modes.
		They can be created from a monolithic kernel with a moderate effort.
		While they provide an interface for rump based drivers they also preserve their monolithic properties and driver stacks. \citep{kantee}
		
		Drivers on top of a rump kernel only need to interface with it and not the underlying kernel.
		That makes this concept portable to highly different platforms such as monolithic or micro kernels.
		This is achieved by stripping away all unneeded components of a kernel and only leaving those required for drivers to work.
		At the lower part of the kernel exists a small and well defined portability layer to interface with the underlying environment.
		These concepts were implemented first by the NetBSD project. \citep{bsd_rump}\citep{fosdem_rump}\citep{rump}
		
		Rump applications and drivers are created using the so called Hypercall API.
		There are two main parts of this API.
		The first one are basic calls for applications such as those for allocating memory or using threads.
		The second is about handling I/O operations and is splitted into a virtual and a physical part.
		The virtualized calls access services provided by the host operating system such as network interfaces and protocols. \citep{rump_man} \citep{rump_platform}
		
		While system calls and access to the host systems interfaces is defined straightforward direct hardware access is not.
		With one exception the rump kernel does not have support to directly map physical memory.
		These mappings are usually represented as files on the host system.
		While these files could be used to map memory into the rump kernel they would also limit the platforms and environments where it can be hosted.
		The only exception to this are vnodes which are inode representations in memory.
		The approach of the rump kernel to solve this problem is to allocate a block of memory and copy the contents of the memory mapped by the host system back and forth.
		This works only because the vnode pages can be accessed by a single consumer at a time.
		Therefore this approach is inapplicable for memory mapped IO or volatile memory. \citep{kantee}
		
		Another important aspect of hardware drivers are interrupts.
		Hardware interrupts usually preempt the CPU which is not supported by the rump kernel.
		Instead they are implemented as host threads which then schedule the handler inside the rump kernel accordingly. \citep{kantee}
		
		While these properties speak against hardware drivers in the first place there is one example of a hardware device driver for USB devices described.
		Yet this example operates on a higher level than direct access to hardware resources.
		The BSD kernel makes USB devices accessible to the user space via \texttt{ugen} the USB generic device support.
		The rump kernel implementation of the USB driver allows to configure the access to specific USB devices at compile time. \citep{kantee} \citep{ugen}
		
		\section{Fuse}
	
	\chapter{Design and Implementation}
	
		Modern System access their hardware through different channels.
		Which one and how these are used depends on the type of hardware and on the requirements to the system.
		These are often a high bandwidth to transmit data or a low latency to react on input.
		Depending on these demands different mechanisms are used.
		
		Peripheral devices are often connected via busses such as the PCI (Peripheral Component Interconnect).
		Those devices can either be user hardware such as graphics card or controller that connect other bus systems or devices.
		The SATA bus is such an example.
		While hard drive disks are connected directly to it a controller is necessary that connects it to the PCI bus which again is connected to the CPU.
		
		While the amount of different busses is large access to them can be broken down to a few mechanisms.
		Higher level accessors that enable more distant devices such as the drive mentioned in the example can be broken down to these few.
		Orders for the driver on the SATA bus are just an abstraction to what needs to be communicated with the SATA controller. \citep{iosystems}
		
		This chapter will evaluate how these resources are handled on Genode and what is needed to enable them on Linux.
		To do this the required resources need to be identified first which is done on an existing kernel such as NOVA.
		Each resource type has different properties so they will be evaluated separately.
		Furthermore general conditions such as the kernels complexity and the integration of these concepts into Genode are discussed.
		
		\section{Requirements}
		
		% no kernel modifications 
		
		To benefit from user space drivers certain requirements need to be fulfilled.
		The driver must run completely inside the user space without any exceptions.
		At the point where it needs to run its own code inside the kernel any security advantage is gone since an attacker could escalade its privileges.
		
		A second requirement are kernel interfaces that allow drivers to work completely without any further modifications to the kernel.
		This is founded on two reasons.
		First it improves operability as drivers can be loaded or patched without any influence on the kernel itself.
		Second, and more importantly, they cannot introduce further errors to the kernel.
		Any modification, even if it is only a small one done to interface with a driver can cause bugs that could compromise the security of the entire system.
		To prevent this the kernel needs to stay untouched.
		
		If an existing kernel, such as Linux, is used to fulfil these needs a suitable interface needs to be added which is then used by the drivers.
		This interface of course is itself a modification to the kernel and needs to be treated as security relevant code.
		Yet it is still much smaller than the drivers it is meant to move to the user space.
		%%%
		
		The general low level resources that are used to communicate with hardware are I/O ports, I/O memory and interrupts.
		While the first one is x86 specific the others can be found on many different architectures.
		
		As discussed in section \ref{sessions} Genode provides so called sessions as resource and communication interface.
		According to the required resources the sessions \texttt{IO\_PORT}, \texttt{IO\_PORT} and \texttt{IRQ} are provided.
		
		Since it is difficult to implement them all correctly without and testing in between it makes sense to pick, implement and test them one by one.
		Testing them requires not only hardware but also drivers that access it.
		To test a single resource an according driver that only depends on this one is required.
		This leads to the next step to analyse the resources a driver needs to function and to categorize these.
		
		In Genode sessions and therefore resources are managed by routes.
		These can be set either implicitly or explicitly.
		The former is used in nearly every configuration that was already available.
		This was often done by setting a generic default route in the parent that would allow any interaction and was inherited by its children.
		Exceptions from this were only settings that otherwise would have been ambiguous.
		
		Listing \ref{implicitroutes} shows the default configuration of the \texttt{rtc\_drv} test which tests the real time clock driver.
		As described above it only specifies a default route which is valid for all children of the parent.
		This route, in line 14 to 16 specifies that any service can use the parent or any child to fulfil its needs.
		This does not help much as all actual required resources are invisible.
		And even if they could be seen somehow this would reflect the maximally used and not the minimally required resources.
		
		\lstset{language=XMl,
			caption={Implicit default routes},
			label=implicitroutes,
			breaklines=true,
			numbers=left,
			stepnumber=1}
		\begin{lstlisting}
<config prio\_levels="2" verbose="yes">
		
	<parent-provides>
		<service name="ROM"/>
		<service name="IRQ"/>
		<service name="IO\_MEM"/>
		<service name="IO\_PORT"/>
		<service name="PD"/>
		<service name="RM"/>
		<service name="CPU"/>
		<service name="LOG"/>
	</parent-provides>
		
	<default-route>
		<any-service> <parent/> <any-child/> </any-service>
	</default-route>
	<default caps="100"/>
		
	<start name="timer">
		<resource name="RAM" quantum="1M"/>
		<provides> <service name="Timer"/> </provides>
	</start>
		
	<start name="rtc\_drv" priority="-1">
		<resource name="RAM" quantum="1M"/>
		<provides><service name="Rtc"/></provides>
	</start>
		
	<start name="rtc\_drv" priority="-1">
		<resource name="RAM" quantum="1M"/>
		<provides><service name="Rtc"/></provides>
	</start>
		
	<start name="test-rtc" priority="-1">
		<resource name="RAM" quantum="1M"/>
	</start>
</config>
		\end{lstlisting}
		
		The solution is to remove the default route.
		This obviously leads to the whole system breaking since no resources are available to anyone.
		The minimal requirement can be achieved by manually adding routes one by one until the desired functionality is available.
		
		The result is listing \ref{explicitroutes} which is already much more verbose.
		It is also stripped down a bit and only shows the parent and one driver.
		The default route of the parent is empty now but the \texttt{rtc\_drv} now has its own section for routes.
		It requires the \texttt{PD} (Protection Domain), \texttt{CPU}, \texttt{LOG} and \texttt{ROM} sessions which are all provided by the parent.
		Those are required by any component running on Genode, no matter if it is a device driver or not.
		
		The more interesting part is the \texttt{IO\_PORT} session route which also points to the parent.
		Since this is the only one other session its also the only other requirement as this component has no access to anything else.
		The essence of this example is that the implementation of the \texttt{IO\_PORT} session on a new platform can be tested with this driver.

		\lstset{language=XMl,
			caption={Explicit routes},
			label=explicitroutes,
			breaklines=true,
			numbers=left,
			stepnumber=1}
		\begin{lstlisting}
<config>
	<parent-provides>
		<service name="ROM"/>
		<service name="IRQ"/>
		<service name="IO\_MEM"/>
		<service name="IO\_PORT"/>
		<service name="PD"/>
		<service name="RM"/>
		<service name="CPU"/>
		<service name="LOG"/>
	</parent-provides>
	<default-route>
	</default-route>
	<default caps="100"/>
		
	<start name="rtc\_drv">
		<resource name="RAM" quantum="1M"/>
		<provides>
			<service name="Rtc"/>
		</provides>
		<route>
			<service name="PD"><parent/></service>
			<service name="CPU"><parent/></service>
			<service name="LOG"><parent/></service>
			<service name="ROM"><parent/></service>
			<service name="IO\_PORT"><parent/></service>
		</route>
	</start>
</config>
		\end{lstlisting}
		
		For the other sessions this needs to be done analogously.
		While the example was straight forward this does not necessarily count for the others.
		The \texttt{IO\_MEM} session also can be tested solely with a single driver, the \texttt{fb\_boot\_drv} in this case.
		But the \texttt{IRQ} is only used in combination with other sessions.
		This results in the order the implementations need to be done with interrupts being the last.
		
		\section{IO Ports}
		
		IO ports or port IO is a mechanism used mainly on the Intel x86 architecture.
		It consists of a hardware bus that is connected directly to the processor and peripheral devices.
		The ports can be used for bidirectional communication similar to a serial interface.
		Access is handled through a specific set of instructions that take addresses and data.
		A special benefit of this mechanism is its atomicity.
		Instructions are guaranteed to be finished before the execution of their successors.
		
		There are 2\textsuperscript{16} addressable ports which transmit 8 bit of data per transaction.
		Consecutive ports can be used to transmit up to 32 bit at once.
		To make use of this the ports need to be aligned on even addresses (for 16 bit transmissions) or on multiples of four (for 32 bit transmissions).
		Other alignments are possible but come with a performance loss.
		
		On modern systems this mechanism often supports legacy hardware such as PS/2 or a floppy disk controllers.
		Also many other architectures lack this type of communication and use memory mapped IO which is also increasingly used with Intel x86 hardware.
		\citep{ioports} \citep{intelmanual}
		
		The implementation of of the \texttt{IO\_Port} session on Linux can be done straight forward.
		This is because IO ports are already available in the user space.
		The only requirement to use them is access to priveledge level 3 which can be achieved with root access on Linux.
		There are several methods that can be used and need to be implemented to use these ports.
		An example are \texttt{unsigned char inb(unsigned short int port)} and \texttt{void outb(unsigned char value, unsigned short int port)} which are used to respectively read and write a single byte to a specific port address.
		To use these functions the permissions need to be granted first.
		This can be done either by \texttt{int iopl(int level)} or \texttt{int ioperm(unsigned long from, unsigned long num, int turn\_on)} which are explained subsequently. \citep{outb} \citep{ioperm} \citep{iopl}
				
		\subsection{iopl}
		
		The first option, \texttt{iopl} grants the calling process a specific privilege level.
		On Linux these levels range from zero to three where zero is the level of a normal process and 3 is the highest one.
		These privileges are also inherited by child processes created by \texttt{fork} or \texttt{execve}. \citep{iopl}
		
		On Genode core would call \texttt{iopl} once it starts and creates the \texttt{IO\_Port} session.
		A component would access these ports through the session interface which also regulates the port ranges.
		
		\subsection{ioperm}
		
		\texttt{ioperm} is a more fine grained option to get the required privileges.
		Instead of \texttt{iopl} it does not give the calling process a higher privilege level but only access to a certain range of IO ports.
		This needs to be specified on the call by passing the starting port and the amount of ports that are accessed consecutively.
		It also does not allow processes to access overlapping port ranges. \citep{ioperm}
		
		The approach on Genode is to call this syscall when a client connects to the \texttt{IO\_Port} session with the required port ranges.
		This would not collide with the checks implemented in Genode but would provide the enforcement of these constraints on kernel level.
		
		\section{Memory mapped IO}
		
		Memory mapped IO is a widely used mechanism to access hardware.
		It maps hardware registers into the physical address space.
		From the view of the operating system it looks as it is part of the available RAM.
		Yet these regions differ in behaviour to conventional registers.
		Accesses to memory mapped IO cannot be cached as they might have side effects on hardware or other registers.
		Even reading might influence the device.
		This is important especially in exception handling where accesses might be repeated.
		
		Memory mapped IO is widely used on different architectures as it provides a clear interface and enables the transfer of substantial amounts of data.
		Also with 64 bit addressing the physical address space is large enough to prevent collisions with conventional RAM.
		\citep{intelmanual}
		
		While memory mapped IO is much more important that IO ports Linux does not provide a good interface to use it from the user space.
		There is already a mechanism to access physical memory ranges from the user space on Linux, \texttt{/dev/mem}.
		This is a special character device that can be used by a user space program to map a physical range of memory into its address space.
		While this would be sufficient to make things "work" it lacks a more fine grained access control.
		
		Any process that is able to open that device and map its memory can access all the available ranges and not only what it is supposed to.
		In newer kernels this has a small restriction that only IO memory can be mapped.
		Before it was even possible to access the whole available memory, even that of the kernel and other processes. \citep{devmem}
		
		Yet the access to only device memory ranges, but all of them, is still insufficient as a driver should only access the ranges its parent allowed it to.
		This leads to the requirement of a more constrainable and controllable access mechanism.
		
		\subsection{Memory device}
		
		The easiest would be using \texttt{/dev/mem} which already has mapped all physical memory into the user space.
		While on early kernel versions it was possible to access the whole memory current versions have the \texttt{CONFIG\_STRICT\_DEVMEM} configuration option enabled which only allows access to IO memory but not arbitrary RAM.
		
		Yet any process that holds a file descriptor can still access all IO ranges and therefore control nearly all hardware devices.
		This cannot be constrained in any way which is a danger to Genodes process isolation.
		While only core is able to open the file descriptor and pass it to a component the component needs to map the memory by itself.
		Since it can map arbitrary regions of memory it would be able to control devices or interfere with other drivers without core having the ability to control or restrict such an action.
		As this strongly violates the security assumptions this option should only be implemented if any other fails. \citep{devmem} 
		
		\subsection{System call}
		
		A more fine grained and better controllable solution would be a custom system call.
		It could be implemented to take the offset and size of the memory region and map it directly into the user space.
		Also Genode specific attributes could be used since there is no constraint in available functionality.
		
		While this is a powerful solution it comes with certain limitations.
		System calls cannot be added by kernel modules and need to be implemented directly inside the kernel.
		This does not only require the the kernel to be compiled for each device but also a manual upgrade each time a new version is released.
		Also a syscall number needs to be chosen that does not collide with any existing one.
		While this sounds easy in the first place it either requires the number registrated by kernel developers to prevent collisions or to reassign it in future versions.
		So beside this being a powerful way to enable user space memory mapping it also requires a higher maintenance over time. \citep{syscall}
		
		\subsection{SysFS}
		
		The Linux \texttt{sysfs} which is located in \texttt{/sys} is a common way to enable communication between user space applications and the kernel.
		This is usually done by accessing files in \texttt{/sys}.
		An implementation of such a driver would provide a file that the arguments are placed into; for example the space separated name, offset and size of the regarded memory region.
		It would then place an correspondingly named device file into ts directory that the user space process can open and map. \citep{sysfs}
		
		As this enables the driver to selectively make memory regions accessible, even to specific users only, this would fit Genodes security model.
		Core would be responsible to set the correct arguments into the input file and the component could open and map the file according to its capabilities.
		
		Yet there are some disadvantages, especially in regards to complexity.
		Mapping a memory region would need multiple file operations.
		Also the direct access to files in \texttt{/sys} is disregarded since the structure of the file system can change.
		To prevent effects of these changes it is recommended to use an abstraction layer such a udev or HAL.
		These dependencies would furthermore increase the complexity of this approach.
		Since Genodes \texttt{base-linux} does not depend yet on sysfs it could be removed from the kernel later.
		That would not be true anymore if this approach was chosen. \citep{sysfs}
		
		\subsection{Fcntl}
		
		Another implementation option is the use of \texttt{fcntl} on a file descriptor of \texttt{/dev/mem}.
		This function is designed to implement custom operation on file descriptor properties such as setting the file status and make the file readable or writeable through this descriptor.
		It is a multiplexing system call that can perform different operations based on its arguments.
		In this case all of these are file specific and custom operations are usually of low complexity or derived from already existing ones.
		Yet it is not clear if the required constraints can be layed upon the file descriptor on \texttt{/dev/mem}. \citep{syscall} \citep{fcntl}
		
		\subsection{Prctl}
		
		Another option, more process than file centered, is \texttt{prctl} which implements custom operations on processes.
		It is similar to \texttt{fcntl} in its nature as a system call multiplexer.
		It implements different operations that manipulate the processes own properties such as thread names.
		Also custom implementations are recommended to be either rather simple or derived from already existing ones.
		The idea is to map a specific part of memory directly into the process.
		However it is questionable if the semantics of mapping memory fit into modifying a processes attributes. \citep{syscall} \citep{prctl}
		
		\subsection{Custom device with ioctl}
		\label{hwio}
		
		While, except for \texttt{sysfs}, most of these options use methods that were not intended to be used that way this is a partially reimplementation of \texttt{/dev/mem} fixing the issues stated above.
		The custom device also makes memory mappable to a process via the file descriptor.
		Yet it supports a custom implemented \texttt{ioctl} that is able to constrain the device accordingly.
		
		While \texttt{ioctl} is similar to \texttt{fcntl} it also supports sending and receiving data to and from the device.
		The data is copied from and to the kernel space accordingly.
		This and the control over the devices implementation allow a constraint to the memory that can be mapped while on the other hand having no dependencies beside \texttt{/dev}.
		It also can be built as a kernel module which makes it loadable at run time. \citep{ioctl}
		
		\section{Interrupts}
		
		Interrupts are asynchronous events sent by external devices.
		Beside the so called interrupt number no further information is transmitted.
		Also this is a single directional channel.
		Interrupts are triggered by a device and received by the CPU.
		
		When an interrupt occurs the execution of the current task is interrupted by the CPU and a handler procedure is called.
		The handler is registered to one of the 18 predefined or 224 user defined interrupts.
		When it is called the only information available is that one of the interrupts it was registered to has been triggered.
		Any further information needs to be acquired through other channels, for example memory mapped IO. \citep{intelmanual}
		
		This mechanism is usually used for devices that wait for events such as keyboards.
		Instead of checking periodically if a key has been pressed it registers an interrupt that is triggered once a key is pressed.
		Then the driver can check which key has been pressed and pass this information to the operating system.
		
		The Linux kernel does not allow to register an interrupt handler in the user space.
		It is possible to see and observer interrupts in \texttt{/proc/interrupts} yet polling them from this file is not feasible as they are often require a low latency.
		This leads to the need of a new mechanism that provides user space access and a reasonable latency.
		
		On Genode interrupts are implemented as threads that wait for a given hardware interrupt.
		Once it is triggered the thread is woken up and calls the interrupt handler.
		It is also masked and cannot receive further hardware interrupts until the handler acknowledged the handling of the last one. \citep{genode}
		
		With this behaviour in mind the interrupt on Linux can be implemented as a blocking read on a special device file.
		The generic way is similar to the one described in section \ref{hwio}.
		A custom device is opened and the file descriptor is configured via \texttt{ioctl}.
		The configuration would set the interrupt number that the handler should be tied to.
		Inside the module it would register on the according interrupt of the Linux kernel.
		
		The interrupt thread in Genode would receive the configured file descriptor and call a read on it.
		The device has implemented the read in such a way that it will not return until the interrupt is triggered inside the kernel.
		Once this happened the read would return and the handling can go on as defined in Genode.
		
		The masking of the interrupt is done by not calling read which.
		This results in ignoring all hardware interrupt that occur in this time.
		An acknowledgement by the handler calls read again and therefore unmasks the interrupt.
		
		This solution implements interrupts on Linux without polling and therefore should gain a feasible latency.
		It also keeps the correct semantics of the implementation in Genode and should not require any workarounds.
		
		\section{Complexity}
		
		With security assumptions in mind enabling resource access for the user space is not the only requirement.
		The Linux kernel is a complex construct with millions of lines of code.
		To reduce this complexity as much unnecessary functionality as possible needs to be removed.
		Beside the removal of drivers that are provided by the user space system such as USB and graphics support also other subsystems that usually are not directly visible to the common user need to be taken care of.
		
		This is especially important for parts that could be used to implement other requirements.
		So it needs to be taken care of that nothing depends on those.
		These systems include \texttt{procfs} and \texttt{sysfs} which many user space interfacing drivers depend on. \citep{sysfs} \citep{procfs}
		
		Also some drivers are required to be removed not only because of complexity but their interference with drivers that should run in the user space.
		While the kernel might even allow multiple entities to access the same range of memory or IO ports this will likely cause errors.
		Since these mechanisms access hardware resources they are highly volatile which also means that changes made by one driver are visible in another accessing the same device.
		To prevent this any resource that is used by a user space driver must not be used by the kernel.
		
		\section{Integration into Genode}
		
		These concepts need to be integrated into Genodes source tree.
		This should be done via a repository as explained in section \ref{repos}.
		Since there is already a Linux specific implementation this should be reused in the solution.
		with these constraints set there are three feasible ways to integrate.
		
		\subsection{Copy base-linux}
		The simplest way to build upon base-linux is creating a copy it in a new base directory.
		The advantage of this approach lies in the fact that there is, beside including the new directory, no need to modify upstream code.
		On the other hand this leads to code duplication and any updates of base-linux probably need to be ported to its modified copy.
		
		\subsection{Include base-linux}
		Creating a new base directory and including the needed contents from base-linux via Makefile fragments.
		While this would include the advantages of the copy based approach there is less to no code duplication.
		The disadvantage here is the complexity due to the build system that does not provide a standard way to include parts of other base directories.
		
		\subsection{Extend base-linux}
		To prevent both code duplication and complex includes the already existing base directory could be used and extended.
		While this approach seems to be easier it has two caveats.
		Since it requires modifications of the original base-linux core the current functionality needs to be maintained.
		This can be done either by creating a hybrid core that is able to run like the current one and on a bare Linux kernel or a switch needs to be added that chooses the target on build time.
		Additionally this code needs to be brought upstream as it cannot be plugged into the source tree like a separate base directory.
	
		\section{Implementation}
		
		Beside implementing the discussed conceptions the environment requires to be prepared.
		This ranges from creating a boot sequence for Genode on Linux and a build process for the required image to acquiring hardware information and providing it in a compatible way.
		Also the Linux kernel needed to be adapted to avoid resource access collisions with drivers running on Genode.
		
		\subsection{Booting Genode on Linux}
		
		The first step was to generate an image that was bootable on Qemu and started Genode on Linux as init process.
		While there already was a Linux target it did only start Genode on the hosts kernel and ran as a user process on the host.
		
		The process for generating and starting bootable images in Genode consists of different parts.
		The \texttt{tool} section in the Genode source tree provides run scripts that build images and prepare the virtual machines.
		Depending on the options set at build time it would build an according system image and start it with the configured settings.
		For Linux there was no image to be built since it was started directly on the host system.
		Also the Qemu starting options were not set since it should not start within Qemu. \citep{genode}
		
		The build time settings are configured inside the build directory unter \texttt{etc/build.conf}.
		These include the used kernel, general launch options and Qemu specific settings.
		The decision whether Linux should be started on the host ore bare metal is done here.
		This setting, \texttt{KERNEL\_RUN\_OPT}, is defined for each kernel.
		Listing \ref{kernellinux} shows the default values for running Linux on the host.
		
		\lstset{language=make,
			numbers=none,
			caption={Default Linux settings},
			label=kernellinux,
			breaklines=true}
		\begin{lstlisting}
KERNEL_RUN_OPT(linux) := --include power_on/linux --include log/linux
		\end{lstlisting}
		
		\lstset{language=make,
			numbers=none,
			caption={Qemu Linux settings},
			label=kernellinux2,
			breaklines=true}
		\begin{lstlisting}
KERNEL_RUN_OPT(linux) := --include power_on/qemu  --include log/qemu --include image/uefi
		\end{lstlisting}
		
		To run Linux on Qemu the same options as for micro kernel were used.
		As shown in listing \ref{kernellinux2} they include starting Qemu and specify an image type to be used.
		There are two types available, \texttt{image/iso} which creates a .iso file that is bootable with a legacy BIOS and \texttt{image/uefi} for systems that only support (U)EFI bootable images.
		
		The image creation itself is done in scripts located in the \texttt{tool} directory and consists of several steps.
		Since the image uses Grub2 to boot a configuration needs to be supplied.
		This is generated by a script depending on the provided image options.
		Following an empty image with a FAT32 file system and a GPT partition table is generated.
		The required files including the built binaries, Grub2 and its configuration are then copied to this image.
		Beside the Linux specific configuration for Grub2 this process was reused from other kernels.
		
		% grub 2
		
		The first stage of the boot process is Grub2 which loads the actual kernel.
		While the micro kernels used in Genode use the Multiboot2 standard Linux requires its own handling.
		It consists of setting the kernel and the so called initial RAM disk, or \texttt{initrd}.
		This process is available in grub via a module called \texttt{linux} that needs to be loaded first.
		A simple configuration to boot Linux is shown in listing \ref{grubcfg}.
		\texttt{vmlinuz} is a gzip compressed Linux kernel image and \texttt{initramfs} the initial RAM file system which is the successor of the legacy initial RAM disk.
		
		\lstset{
			numbers=left,
			caption={Grub2 configuration to boot Linux},
			label=grubcfg,
			breaklines=true}
		\begin{lstlisting}
menuentry 'Genode on Linux' {
	insmod linux
	linux /vmlinuz
	initrd /initramfs
}
		\end{lstlisting}
		
		%initramfs
		
		
		\subsection{hwiodev}
		
		\subsection{Session implementation}
		
		\subsection{Platform info}
	
	\chapter{Evaluation}
	
		The working state of Genodes device drivers is the evaluation metric that this thesis is measured against.
		The first part of this is getting an overview over the existing drivers and categorize them by their required resources.
		Based on the implemented resources and the functionality of different drivers the state of each resource can be determined.
		
		\section{Resource requirements}
		
		The resource requirements drivers have do not refer to generic resources such as CPU time and RAM but to I/O that it available to communicate with hardware.
		More specific these are I/O ports, I/O memory and interrupts.
		In Genode they are represented by the \texttt{IO\_PORT}, \texttt{IO\_MEM} and \texttt{IRQ} sessions.
		
		To verify and analyse the drivers a reference platform is required.
		To fulfil this a Lenovo ThinkPad X260 was chosen.
		This was done due to the fact that most of the internal devices are supported by drivers available on Genode.
		On the other hand this choice limits the driver selection to the Intel x86 architecture.
		
		Some of the selected drivers were available due to the platform such as the real time clock which is defined for the X86 platform.
		Others such as USB can be used on any device since the controller interface has been standardized.
		More complex devices as the network interface card driver are device specific and do not work on any platform.
		A breakdown on which drivers are tested and a short description of each one is shown in table \ref{driver_selection}.
		
		\begin{table}[]
			\centering
			\begin{tabular}{r|l}
				Driver        & 
				Description 
				\\ \hline
				platform\_drv & 
				Enables many other drivers through resource management
				\\ \hline
				acpi\_drv     &
				Advanced Configuration and Power Interface,
				\\& often required to gain information about resources \citep{acpi_spec}
				\\ \hline
				fb\_boot\_drv &
				Framebuffer driver that uses the (U)EFI provided graphics
				\\& through Multiboot2, only available when booted via (U)EFI  \citep{multiboot2}
				\\ \hline
				rtc\_drv      &
				x86 specific real time clock device driver
				\\ \hline
				usb\_drv      &
				Generic xHCI USB driver \citep{xhci}
				\\ \hline
				intel\_fb     &
				Intel i915 framebuffer driver, supported by the integrated
				\\& Intel HD Graphics 520 \citep{x260}
				\\ \hline
				ahci\_drv     &
				AHCI/SATA disk driver
				\\ \hline
				fb\_drv       &
				VESA framebuffer driver, only available if booted via legacy BIOS
				\\ \hline
				nic\_drv      &
				Intel e1000 network driver, supported by the integrated
				\\& Intel I219 chipset \citep{x260}
				\\  \hline
				audio\_drv    &
				Audio driver, supported by the integrated
				\\& Realtek ALC3245 chipset \citep{x260}
			\end{tabular}
			\caption{Used drivers}
			\label{driver_selection}
		\end{table}
		
		A special case is the platform driver.
		While on one hand it is a common device driver itself it also functions as a gateway for resource requests of other drivers, especially those for PCI devices.
		If such a device driver requires access to a hardware resource it does not do this directly but through a request at the platform driver which then requests the actual session from core.
		This implies that such a driver additionally requires the resources the platform driver itself needs to work.
		To properly display this the platform driver will be listed as a resource by itself and it will be marked which session was requested.
		
		Another exemption from the conventional resources is the timer.
		While it is not hardware dependent it relies on the underlying kernel.
		Even though it was already available on Linux it is needed to enable this platform and is listed here for completeness.
		
		The requirement analysis of was done by creating scenarios with explicit routes only.
		The configurations were reduced to the point that taking away any of these resources would make the driver fail.
		The results are visualized in table \ref{drivers}.
	
		\begin{table}[]
			\centering
			\begin{tabular}{r|c|c|c|c|c|c|c|c}
				& \rotatebox[]{90}{Timer}
		& \rotatebox[]{90}{IO\_PORT}
		& \rotatebox[]{90}{IO\_MEM}
		& \rotatebox[]{90}{IRQ}
		& \rotatebox[]{90}{Platform driver}
		& \rotatebox[]{90}{IO\_PORT (Platform)}
		& \rotatebox[]{90}{IO\_MEM (Platform)}
		& \rotatebox[]{90}{IRQ (Platform)} \\ \hline
				
				platform\_drv &   & x &   & &   &   &   &   \\ \hline
				acpi\_drv     &   &   & x & &   &   &   &   \\ \hline
				fb\_boot\_drv & x &   & x & &   &   &   &   \\ \hline
				rtc\_drv      &   & x &   & &   &   &   &   \\ \hline
				usb\_drv      & x &   &   & & x & x & x & x \\ \hline
				intel\_fb     & x &   & x & & x & x & x & x \\ \hline
				ahci\_drv     & x &   & x & & x & x & x & x \\ \hline
				fb\_drv       & x & x & x & & x & x &   &   \\ \hline
				nic\_drv      & x &   &   & & x & x & x & x \\ \hline
				audio\_drv    & x &   &   & & x & x & x & x
			\end{tabular}
			\caption{Device driver resource requirements}
			\label{drivers}
		\end{table}

			
		A note here is that all drivers using the platform driver also require the \texttt{IO\_PORT} session.
		This has two reasons.
		First of all the platform driver itself requires I/O ports so this dependency is basically inherited from anything depending on it.
		One could argue that creating a independent version of a particular driver would change this.
		Yet the assumption was to use unmodified drivers which would have been broken by any change to a driver itself.
		Secondly since the driver is failing to function on the removal of this resource it is treated as a requirement.
		
		\section{Tested drivers}
		
		Since only I/O port and I/O memory support was actually implemented solely drivers that do not need interrupt have been tested.
		The tests of the remaining have been done in a Qemu virtual machine and on the Lenovo ThinkPad X260.
		
		The \texttt{IO\_PORT} session worked without any problems.
		It has been tested with the real time clock test that could be run unmodified.
		This is also the configuration shown in listing \ref{implicitroutes}.
		Secondly the platform driver was tested separately.
		To verify its working state the component \texttt{pci-test} was used which acquires information about available PCI devices and prints them to the log.
		This test showed the correct devices without any problems on both testing platforms.
		
		The \texttt{IO\_MEM} session had some medium issues.
		The first test was done with \texttt{fb\_boot\_drv} which maps a single physical address and provides a framebuffer interface.
		A component testing the framebuffer by drawing different colours to the screen was used and showed the expected results on both the virtual machine and the laptop.
		
		The \texttt{acpi\_drv} and \texttt{fb\_drv} were more difficult.
		Both of them map and release different chunks pf physical memory.
		The releasing regularly caused segmentation faults.
		The exact cause could not be found but preventing the release by commenting out the specific part of the code caused the \texttt{acpi\_drv} to announce the correct information read from the ACPI tables.
		While this comes with a somewhat broken state and memory leaks it shows that the conceptual design is working.
		
		While the \texttt{fb\_drv} was also affected by the segmentation faults this issue was worked around with removal of the actual memory releases.
		Yet there was a second issue that caused the driver to hang arbitrarily at some point.
		Only two tests did work and showed the output of the framebuffer test used with \texttt{fb\_boot\_drv}.
		A workaround was to add log outputs to specific actions of the driver slowing it down.
		This leads to the assumption that these failures are caused by a race condition.
		Unfortunately this mitigation only worked in the virtual machine.
		On the laptop the driver did not come up.
		Furthermore it hung at a point that never caused any problems in the virtual machine.
		Due to the constrained debug methods on this platforms this issue was not further researched.
	
	\chapter{Conclusion and future work}
	
	\bibliographystyle{unsrtnat}
	\bibliography{sources}
	
\end{document}
